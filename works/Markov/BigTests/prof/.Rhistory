setwd("A:\\Documents\\conmet\\github\\works\\Markov\\BigTests\\prof")
data2 <- read.table("outTimeSerial_Tick.csv", h=T, sep=";")
data2 <- data2[order(data2$k, data2$n),]
attach(data2)
data3 <- read.table("outTimeParal_Tick.csv", h=T, sep=";")
data3 <- data3[order(data3$k, data3$n),]
attach(data3)
plot(data2$time, ylab="time")
plot(data3$time, ylab="time")
plot(data2$time, ylab="time")
plot(data3$time, ylab="time")
plot(data3$time, ylab="time")
sd(data2$time)
sd(data3$time)
plot(data2$time, ylab="time")
plot(data3$time, ylab="time")
plot(data2$time, ylab="time")
plot(data2$time, ylab="time", col="black")
points(data3$time, col="red")
lines(h=mean(data2$time), col="black")
lines(h=mean(data3$time), col="red")
plot(data2$time, ylab="time", col="black")
points(data3$time, col="red")
abline(h=mean(data2$time), col="black")
abline(h=mean(data3$time), col="red")
able("out_TRUE_RND_BIG.csv", h=T, sep=";")
# Reorganisation des lignes en les triant par k puis par n
data1 <- data1[order(data1$k, data1$n),]
attach(data1)
data1 <- read.table("out_TRUE_RND_BIG.csv", h=T, sep=";")
# Reorganisation des lignes en les triant par k puis par n
data1 <- data1[order(data1$k, data1$n),]
attach(data1)
subset(data1, m==10000)$time
plot(data1$time)
plot(k, count1)
# C'est assez moche avec les options par defaut, mais on peut mieux faire
# en jouant avec les options
plot(k, count1, pch=3, xlab="k", ylab="count1 (tri des prefixes)",  cex.lab=0.9, cex.axis=0.8, cex=0.8)
summary(lm(count1 ~ k))
# La pente de la regression lineaire vaut 31.59 et elle n'est pas statistiquement
# differente de 0 (p-value Pr(>|t|) largement superieure a 0.05).
# Le coefficient de determination (R^2) vaut 10^-12, donc quasiment 0.
# On peut l'interpreter comme le pourcentage de variance (de count1) expliquÃ© par
# les variations du paramÃ¨tre k.
abline(lm(count1 ~ k)) # on voit bien que la pente est quasi nulle
# Verifiez ici que count1 ne depend pas non plus de m
plot(m, count1)
# C'est assez moche avec les options par defaut, mais on peut mieux faire
# en jouant avec les options
plot(m, count1, pch=3, xlab="m", ylab="count1 (tri des prefixes)",  cex.lab=0.9, cex.axis=0.8, cex=0.8)
summary(lm(count1 ~ m))
# La pente de la regression lineaire vaut 45.04 et elle n'est pas statistiquement
# differente de 0 (p-value Pr(>|t|) largement superieure a 0.05).
# Le coefficient de determination (R^2) vaut 10^-28, donc quasiment 0.
# On peut l'interpreter comme le pourcentage de variance (de count1) expliquÃ© par
# les variations du paramÃ¨tre m.
abline(lm(count1 ~ m))
plot(n, count1, pch=3, xlab="n", ylab="count1 (tri des prefixes)",  cex.lab=0.9, cex.axis=0.8, cex=0.8)
# Faire le fit lineaire de count1 en fonction de n
summary(lm(count1 ~ n))
# Quel R^2 obtenez-vous ?
# R^2 = 0.9994 environ Ã©gal Ã  1
# Ajoutez la droite de regression sur le graphique.
abline(lm(count1 ~ n))
log2n <- log(n,2)
z <- n*log2n
plot(z, count1, pch=3, xlab="n.log2(n)", ylab="count1 (tri des prefixes)",  cex.lab=0.9, cex.axis=0.8, cex=0.8)
summary(lm(count1 ~ z + 0)) # le '+ 0' force une ordonnee a l'origine nulle
# R^2 = 1
# On a donc ameliore le fit en prenant en compte notre connaissance de l'algo.
# On pourra faire des predictions plus precises
abline(lm(count1 ~ z + 0))
lmcount1 <- lm(count1 ~ n + k + m)
summary(lmcount1)
# On voit que seul le parametre n a un coefficient statistiquement different de 0
# (cf les p-values
c3 <- count3/m
plot(n, c3, col=k, pch=3, xlab="Taille du texte original (n)", ylab="Nb d'appels a wordncmp par mot en sortie", cex.lab=0.9, cex.axis=0.8, cex=0.8)
lm2 <- lm(c3[k==2] ~ 0 + n[k==2] )
abline(lm2, col=2)
summary(lm2) # R-squared = 0.8534
lm3 <- lm(c3[k==3] ~ 0 + n[k==3])
abline(lm3, col=3)
summary(lm3) # R-squared = 0.6567
lm4 <- lm(c3[k==4] ~ 0 + n[k==4])
abline(lm4, col=4)
summary(lm4) # R-squared = 0.4577
lm5 <- lm(c3[k==5] ~ 0 + n[k==5])
abline(lm5, col=5)
summary(lm5) # R-squared = 0.4406
lm6 <- lm(c3[k==6] ~ 0 + n[k==6])
abline(lm6, col=6)
summary(lm6) # R-squared = 0.4124
lm7 <- lm(c3[k==7] ~ 0 + n[k==7])
abline(lm7, col=7)
summary(lm7) # R-squared = 0.4236
legend(0, 120, c("k=2", "k=3", "k=4","k=5","k=6", "k=7"), lty="solid", lwd=2, col=2:7, bty="n", cex=0.8)
legend(0, 120, c("k=2", "k=3", "k=4","k=5","k=6", "k=7"), lty="solid", lwd=2, col=2:7, bty="n", cex=0.8)
# Ce serait plus joli d'avoir une echelle log en x.
plot(log(n), c3, col=k, pch=3, xlab="log(taille du texte original)", ylab="Nb d'appels a wordncmp par mot en sortie", cex.lab=0.9, cex.axis=0.8, cex=0.8)
# On ne peut plus utiliser abline pour dessiner le fit lineaire
legend(8.2, 120, c("k=2", "k=3", "k=4","k=5","k=6", "k=7"), lty="solid", lwd=2, col=2:7, bty="n", cex=0.8)
legend(8.2, 120, c("k=2", "k=3", "k=4","k=5","k=6", "k=7"), lty="solid", col=2:7, bty="n")
legend(c("k=2", "k=3", "k=4","k=5","k=6", "k=7"), lty="solid", col=2:7, bty="n")
plot(log(n), c3, col=k, pch=3, xlab="log(taille du texte original)", ylab="Nb d'appels a wordncmp par mot en sortie", cex.lab=0.9, cex.axis=0.8, cex=0.8)
lines(log(n[k==2]), lm2$fitted.values, col=2)
lines(log(n[k==3]), lm3$fitted.values, col=3)
lines(log(n[k==4]), lm4$fitted.values, col=4)
lines(log(n[k==5]), lm5$fitted.values, col=5)
lines(log(n[k==6]), lm6$fitted.values, col=6)
lines(log(n[k==7]), lm7$fitted.values, col=7)
legend(8.2, 120, c("k=2", "k=3", "k=4","k=5","k=6", "k=7"), lty="solid", lwd=2, col=2:7, bty="n", cex=0.8)
# Pour final
# Faites le graphique du temps CPU en fonction de count1.
plot(cputime, count1, pch=3, xlab="cputime", ylab="count1 (tri des prefixes)",  cex.lab=0.9, cex.axis=0.8, cex=0.8)
# Faire le fit lineaire de count1 en fonction de n
summary(lm(count1 ~ cputime))
# Quel R^2 obtenez-vous ?
